Código FUNDAE: DATOS


¿Cómo saber si elegir un modelo de regresión o de clasificación?

En base a la variable dependiente/columna/target "y".

1. REGRESIÓN: Si es un número continuo y existe un número muy elevado de posibilidades, es regresión: precios de casas, números que tienen decimales y necesitamos aproximaciones precisas.

2. CLASIFICACIÓN: Si es un número/texto/categoría muy acotado entre un conjunto de opciones, es clasificación: por ejemplo si es spam si o no, a qué grupo pertenece un cliente ( grupo a, grupo b, grupo c). 

3. SERIES TEMPORALES: (Regresión) Para el tema de fechas, el concepto se llama series temporales, lo normal es utilizar una fecha en la entrada, para ello se puede descomponer el día, mes, año en columnas separadas y usarlas en la entrada. Predicciones más avanzas utilizan la fecha completa usando librerías como statsmodels, redes neuronales recurrentes, etc. Requiere preprocesados especiales para fechas.

4. No supervisado: PCA, Clustering...


## CLASES SCIKIT LEARN

Algoritmos clásicos de Machine Learning:

* Regresión:
    * LinearRegression
    * KNeighborsRegressor
    * SVR
    * DecisionTreeRegressor


* Clasificación: binaria o multiclase
    * LogisticRegression
    * KNeighborsClassifier
    * SVC
    * DecisionTreeClassifier


Algoritmos de conjunto (avanzado), combinan múltiples algoritmos de los anteriores:

sklearn.ensemble

* Regresión:
    * RandomForestRegressor
    * AdaBoostRegressor
    * GradientBoostingRegressor

* Clasificación: binaria o multiclase
    * RandomForestClassifier
    * AdaBoostClassifier
    * GradientBoostingClassifier


Validación de modelos:
    * train_test_split en 80/20 por ejemplo
    * cross_validate


## PREPROCESADOS

técnicas que aplicamos a los datos antes del modelado con el fin de preparar los datos para que sean lo más idóneos para el modelo en cuestión.

* Imputar valores faltantes: 
    * SimpleImputer (media, mediana, moda, constante)
    * IterativeImputer y KNNImputer para predecir el valor faltantes.

* Codificación de categóricos a numéricos (encoding):
    * OneHotEncoder (X) (equivalente a get_dummies)
    * LabelEncoder (y) (equivalente a .map) (Clasificación binaria o multiclase)
        * NO utilizar el Label encoder en la X ya que puede introducir un orden/ficticio en las columnas de entrada y el algoritmo al entrenar le da más importancia a unos valores que a otros.

* Escalado de datos numéricos: 
    * Convertir todas las columnas numéricas a un rango de [0 a 1] antes del get_dummies para escalar las las columnas con números muy distintos, por ejemplo: edad, salario.
    * MinMaxScaler

* Transformar la distribución de los datos a una distrución normal y simétrica sin sesgos:
    * QuantileTransformer

* Balancear datos categóricos:
    * SMOTE de imblearn

* Reducción de la dimensionalidad, eliminar información no relevante
    * PCA (Técnica de aprendizaje no supervisado)
        * Pasar de 100 columnas a 50 columnas. No quita columnas, hace una transformación y se queda con menos columnas (transformadas) pero tratando de conservar la máxima información de valor posible.





* Discretización (Codificación de categórico a numérico):
    * Binarizer  
    * KBinsDiscretizer
    * Si una columna numérica no correlaciona mucho con lo que queremos predecir, una opción es discretizarla y luego hacer un get_dummies y ver si eso nos da alguna columna que correlacione más


Formas de usar los preprocesados:

* Opción 1: fit_transform()
* Opción 2: fit(), transform()


