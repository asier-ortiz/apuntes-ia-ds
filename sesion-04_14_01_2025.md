
CÓDIGO FUNDAE: MARCADO

## DATASETS

* Carpeta data en "Archivos"
* Kaggle: https://www.kaggle.com/datasets
* ML UCI: https://archive.ics.uci.edu/
* Gobierno de España: https://datos.gob.es/es/catalogo?res_format_label=CSV
* Google Datasets: https://datasetsearch.research.google.com/
* OpenML: https://www.openml.org/search?type=data&sort=runs&status=active
* AEMET: clima y tiempo
* THE WEATHER CHANNEL
* Librerías de Python:
    * requests
    * Beautiful Soup scrapeo de datos de páginas HTML
        * Ético y legal: términos y condiciones de las páginas web
        * Conexión HTTP para obtener el HTML
        * Motivación: solemos necesitar scrapear datos cuando no tenemos datasets o los tenemos pero queremos enriquecerlos.
        * VPN, Tor,
    * Selenium
    * Acceso vía API


* Las propias librerías:
    * Seaborn
    * Plotly
    * Scikit learn
    * TensorFlow

## CARGA DE DATOS

### NUMPY

* np.genfromtxt

RECOMENDACIÓN: si los datos tienen más de 1 columna entonces cargar los datos mejor con Pandas.


### PANDAS

* pd.read_csv
* pd.read_excel
* pd.read_sql
* pd.read_json

Atributos:

* df.shape
* df.ndim
* df.dtypes

Funciones:

* df.describe()
* df.describe(include='all')
* df.head()
* df.tail()

Renombrado:

* df.rename()
* df.read_csv('dataset.csv', names=['col1'])

Crear/Actualizar columna:
* df['col2'] = df['columna 2']

Acceder a columnas:
* df['col']
* df.col

Borrar columnas:
* df.drop(columns=['PassengerId'],inplace=True)

Filtrar datos:
* df[df['Year] >= 1990]

Exportar datos:

* to_csv()

Detectar nulos

Borrar nulos

## ENTREGAS

* Actividad Google Colab individual: regresión con el dataset tips

* Despliegue de modelos en GCP individual