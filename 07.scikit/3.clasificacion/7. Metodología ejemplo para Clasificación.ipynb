{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CUADERNO DE TRABAJO PARA CLASIFICACIN\n",
    "\n",
    "Vamos a trabajar y comprender cada tarea que compone un problema de modelado predictivo de aprendizaje automtico:\n",
    "1. Carga de fuentes de datos\n",
    "2. Comprensin de los datos mediante:\n",
    "    1. Estadstica descriptiva\n",
    "    2. Visualizacin.\n",
    "3. Preparacin del modelo.\n",
    "    1. Pre-procesar los datos para describir mejor la estructura del problema.\n",
    "    2. Seleccin de caractersticas.\n",
    "4. Evaluacin de los algoritmos. \n",
    "    1. Remuestreo (para evaluar el rendimiento)\n",
    "    2. Mtricas\n",
    "    3. Comprobacin puntual de una serie de algoritmos utilizando su propio conjunto de prueba.\n",
    "    4. Comparacin y seleccin de modelos\n",
    "5. Mejora de la precisin del modelo\n",
    "    1. Mejora de resultados utilizando mtodos de conjuntos - Ensembles.\n",
    "    2. Mediante el ajuste de parmetros de algoritmos - Tuning.\n",
    "6. Cerrar el modelo y lo dejamos disponible para su uso futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Carga de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lo primero que aprenderemos es a cargar datos. El formato ms comn para los datos de aprendizaje automtico son los archivos CSV. \n",
    "Hay varias formas de cargar un archivo CSV en Python. Podemos ver 3 formas de cargar los datos:\n",
    "1. Cargando archivos CSV con la biblioteca estndar de Python.\n",
    "2. Cargando archivos CSV con NumPy.\n",
    "3. Cargando archivos CSV con Pandas.\n",
    "\n",
    "La **API de Python** proporciona el mdulo CSV y la funcin reader() que se pueden usar para cargar archivos CSV. Una vez cargado, puede convertir los datos CSV a una matriz NumPy y usarlos para aprendizaje automtico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Carga de CSV utilizando la librera estandar de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy\n",
    "\n",
    "fichero = './pima-indians-diabetes.data.csv'\n",
    "raw_datos_sp = open(fichero, 'rt')\n",
    "reader = csv.reader(raw_datos_sp, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "x = list(reader)\n",
    "datos = numpy.array(x).astype('float')\n",
    "print(datos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.Puedes cargar sus datos CSV usando NumPy y la funcin numpy.loadtxt(). \n",
    "Esta funcin no asume ninguna fila de encabezado y todos los datos tienen el mismo formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "\n",
    "fichero = './pima-indians-diabetes.data.csv'\n",
    "datos_np = open(fichero, 'rt')\n",
    "datos = loadtxt(datos_np , delimiter=\",\") \n",
    "print(datos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.Carga de CSV desde URL utilizando Pandas y la funcin pandas.read_csv():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datos=pd.read_csv('./pima-indians-diabetes.data.csv', header=None) \n",
    "datos.head()\n",
    "\n",
    "# Ponemos los nombres a las columnas basndonos en la web citada\n",
    "datos.columns=['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI', 'DiabetesPedigree','Age','Outcome'] \n",
    "datos.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Vemos qu datatypes ha adjudicado por defecto por si tuviramos que modificarlos\n",
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Para averiguar el rango de valores que toma cada atributo usamos el comando .describe \n",
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Vemos que no hay valores faltantes en ninguna columna\n",
    "datos.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Comprensin\n",
    "## 2.1 Analtica Descriptiva\n",
    "Este paso nos permite prepararnos para conocer y comprender los datos. Veamos 7 pasos interesantes para comprender mejor nuestros datos de aprendizaje automtico con Python. Los pasos son:\n",
    "1. Echar un vistazo a sus datos en bruto (sp - sin procesar).\n",
    "2. Revisar las dimensiones del dataset.\n",
    "3. Revisar los tipos de datos de los atributos en sus datos.\n",
    "4. Resumir la distribucin de instancias entre clases en nuestro dataset.\n",
    "5. Resumir nuestros datos utilizando estadsticas descriptivas.\n",
    "6. Comprender las relaciones en nuestros datos utilizando correlaciones.\n",
    "7. Revisar el sesgo de las distribuciones de cada atributo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">### 1. Echar un vistazo a sus datos en bruto (sp - sin procesar). \n",
    "Nada como ver los datos en bruto. Nos va a revelar informacin que no se puede obtener de otra manera. Tambin nos permite dejar muestras que pueden convertirse en ideas sobre cmo pre-procesar y manejar los datos mejor en nuestras tareas de aprendizaje automtico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " # 1. Echamos un vistazo a las 20 primeras filas\n",
    "    \n",
    "from pandas import read_csv\n",
    "\n",
    "fichero = './pima-indians-diabetes.data.csv'\n",
    "nombres = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'] \n",
    "datos = read_csv(fichero, names=nombres)\n",
    "vistazo = datos.head(20)\n",
    "print(vistazo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">**Comprensin:** Podemos ver que la primera columna enumera el nmero de fila, lo cual es til para hacer referencia a una observacin especfica a posteriori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">### 2. Revisar las dimensiones del dataset. \n",
    "Conocer en detalle la cantidad de datos que tenemos (filas y columnas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.Dimensiones de nuestros datos (shape)\n",
    "shape = datos.shape \n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> **Comprensin:**\n",
    "- **Demasiadas filas y algoritmos** pueden tardar demasiado en entrenarse. Muy pocas y quizs no tengamos suficientes datos para entrenar los algoritmos.\n",
    "- **Demasiados atributos y pocos algoritmos** pueden tener bajo rendimiento debido al problema de la dimensionalidad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">### 3. Revisar los tipos de datos de los atributos en sus datos. \n",
    "Usando simplemente dtypes dentro del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3.Tipos de datos por cada atributo\n",
    "tipos = datos.dtypes \n",
    "print(tipos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">**Comprensin:** Podemos ver que la mayora de los atributos son enteros, y que la mass y pedi son tipos de puntos flotantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">### 4. Resumir la distribucin de instancias entre clases en nuestro dataset (para modelos de clasificacin). \n",
    "En los problemas de clasificacin, debemos saber cmo de equilibrados estn los valores de clase. Con comunes los problemas muy desequilibrados (muchas ms observaciones para una clase que para otra) y pueden necesitar de un tratamiento especial en la etapa de preparacin de datos del proyecto. \n",
    "Con Pandas se puede obtener rpidamente una idea de la distribucin del atributo de clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4.Resumir la distribucin de instancias entre clases en nuestro dataset # (para modelos de clasificacin)\n",
    "cuenta_clases = datos.groupby('class').size()\n",
    "print(cuenta_clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">**Comprensin:** Podemos ver que hay casi el doble de observaciones con clase 0 (sin aparicin de diabetes) que con clase 1 (aparicin de diabetes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">### 5. Resumir nuestros datos utilizando estadsticas descriptivas. \n",
    "Es verdad que podemos crear ms resmenes de los que podemos revisar, pero la funcin describe() de los DataFrame enumera 8 estadsticas de cada atributo: Recuento, Media, Desviacin estndar, Valor mnimo, Percentil 25, Percentil 50 (mediana), Percentil 75 y Valor mximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " # 5.Resumen estadstica descriptiva\n",
    "from pandas import set_option\n",
    "set_option('display.width', 100) \n",
    "set_option('precision', 3) \n",
    "descripcion = datos.describe() \n",
    "print(descripcion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">**Comprensin:** Al describir nuestros datos de esta manera, tenemos posibilidad de revisar las observaciones de los resultados en detalle. Esto es til tambin para revisar la presencia de valores de NA para datos faltantes o distribuciones llamativas para atributos.\n",
    "- *Hay un par de llamadas a la opcin pandas.set() que nos permite cambiar la precisin de los nmeros y la amplitud de la salida, pero lo hacemos para que sea ms legible para este ejemplo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">### 6. Comprender las relaciones en nuestros datos utilizando correlaciones (relacin entre dos variables y su variabilidad conjunta). \n",
    "El mtodo ms comn para calcular la correlacin es el coeficiente de correlacin de Pearson, que asume una distribucin normal de los atributos involucrados:\n",
    "- Una correlacin de -1 o 1 muestra una correlacin negativa o positiva completa, respectivamente. \n",
    "- Mientras que un valor de 0 no muestra ninguna correlacin en absoluto. \n",
    "\n",
    ">Algunos algoritmos de aprendizaje automtico (la regresin lineal y logstica), pueden tener un rendimiento deficiente si existen atributos muy correlacionados en nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " # 6.Parejas de correlaciones de Pearson\n",
    "correlaciones = datos.corr(method='pearson') \n",
    "print(correlaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">**Comprensin:** La matriz enumera todos los atributos en la parte superior y en el lateral, para dar una correlacin entre todos los pares de atributos (dos veces, porque la matriz es simtrica). Puede ver la lnea diagonal a travs de la matriz desde la esquina superior izquierda hasta la esquina inferior derecha de la matriz que muestra la correlacin perfecta de cada atributo consigo mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">### 7. Revisar el sesgo de las distribuciones de cada atributo (distribuciones univariadas). \n",
    "**El sesgo (skew)** se refiere a una distribucin que se supone gaussiana (normal o curva de campana) que se desplaza o aplasta en una direccin u otra. Muchos algoritmos de aprendizaje automtico asumen una distribucin gaussiana. \n",
    "\n",
    ">Saber que un atributo tiene un sesgo nos permitir realizar una preparacin de datos que tenga en cuenta esto y corregirlo para mejorar la precisin de nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 7.Sesgo por cada atributo\n",
    "skew = datos.skew() \n",
    "print(skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">**Comprensin:** El resultado de sesgo muestra un sesgo positivo (derecha) o negativo (izquierda). Los valores ms cercanos a cero muestran menos sesgo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2. Visualizacin\n",
    "La forma ms rpida de aprender ms sobre sus datos es usar la visualizacin de datos. Est orientada a comprender sus datos para obtener los mejores resultados de los algoritmos de aprendizaje automtico.\n",
    "\n",
    "Se suele trabajar con diagramas univariadas que se utilizan para comprender cada atributo de nuestro dataset de forma independiente:\n",
    "- Histogramas.\n",
    "- Diagramas de densidad.\n",
    "- Diagramas de caja y bigotes (Box & Whisker)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 1. Diagramas univariados. Histogramas\n",
    "Los histogramas agrupan los datos en **contenedores (bins)** y le proporcionan un recuento del nmero de observaciones en cada contenedor.\n",
    "\n",
    "De la forma de los contenedores, puede obtener rpidamente una idea de si un atributo es **gaussiano, sesgado** o incluso tiene una distribucin **exponencial**. Tambin puede ayudarte a ver posibles valores atpicos (**outliers**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Histogramas univariados\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "\n",
    "fichero = './pima-indians-diabetes.data.csv'\n",
    "nombres = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "datos = read_csv(fichero, names=nombres)\n",
    "\n",
    "datos.hist()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 2. Diagramas univariados. Densidad\n",
    "Los grficos de densidad son otra forma de obtener una idea rpida de la distribucin de cada atributo. Las parcelas se ven como un histograma abstracto con una curva suave dibujada a travs de la parte superior de cada contenedor (bin), como lo veamos con los histogramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Diagramas de densidad univariada\n",
    "\n",
    "datos.plot(kind='density', subplots=True, layout=(3,3), sharex=False)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 3. Diagramas univariados.  Caja y bigotes (Box & Whisker)\n",
    "Otra forma til de revisar la distribucin de cada atributo es usar los diagramas de caja y bigotes o los grficos de caja para abreviar.\n",
    "\n",
    ">Los diagramas de caja resumen la distribucin de cada atributo, trazando una lnea para la mediana (valor medio) y un cuadro alrededor de los percentiles 25 y 75 (el 50% medio de los datos).\n",
    "\n",
    ">Los **bigotes** dan una idea de la dispersin de los datos y los puntos fuera de los bigotes muestran valores de valores atpicos candidatos (valores que son 1.5 veces mayores que el tamao de la dispersin del 50% medio de los datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Diagrama de caja y bigotes\n",
    "\n",
    "datos.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 4. Diagramas Multivariados. Matriz de Correlacin\n",
    "La correlacin da una indicacin de cmo de relacionados estn los cambios entre dos variables:\n",
    "- Si dos variables cambian en la misma direccin, se correlacionan positivamente. \n",
    "- Si cambian juntos en direcciones opuestas (uno sube, uno baja), entonces estn correlacionados negativamente.\n",
    "\n",
    ">Puedes calcular la correlacin *entre cada par de atributos*. Esto se llama una matriz de correlacin. Luego puede trazar la matriz de correlacin y tener una idea de qu variables tienen una alta correlacin entre s.\n",
    "\n",
    ">Est muy bien saberlo, ya que algunos algoritmos de aprendizaje automtico, como la regresin lineal y logstica, pueden tener un bajo rendimiento si hay variables de entrada altamente correlacionadas en sus datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#1.Diagrama de la matriz de correlacin (multivariante)\n",
    "import numpy as np\n",
    "\n",
    "correlaciones = datos.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dibujamos la matriz de correlacin (genrica)\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlaciones, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Dibujamos la matriz de correlacin\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlaciones, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = numpy.arange(0,9,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(nombres)\n",
    "ax.set_yticklabels(nombres)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 5. Matriz de dispersin\n",
    "Un diagrama de dispersin muestra la relacin entre dos variables como puntos en **2 dimensiones**, un eje para cada atributo. Puede crear un diagrama de dispersin para cada par de atributos en sus datos.\n",
    "\n",
    ">Dibujar todos estos grficos de dispersin juntos se llama una **matriz de grficos de dispersin**.\n",
    "\n",
    ">Los diagramas de dispersin son tiles para detectar relaciones estructuradas entre variables, como un resumen de la relacin entre dos variables con una lnea. Los atributos con relaciones estructuradas tambin pueden estar correlacionados y ser buenos candidatos para ser eliminados de su conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(datos)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "# 3. Preparacin del modelo\n",
    "## 3.1 Pre-procesado\n",
    "Muchos algoritmos de aprendizaje automtico hacen suposiciones sobre sus datos. A menudo es una muy buena idea preparar sus datos de tal manera que exponga mejor la estructura del problema a los algoritmos de aprendizaje automtico que pretende utilizar.\n",
    "\n",
    "Con la ayuda de scikit-learn podemos:\n",
    "- **a) Re-escalar los datos.**\n",
    "- **b) Estandarizar los datos.**\n",
    "- **c) Normalizar los datos.**\n",
    "- **d) Binarizar datos.**\n",
    "\n",
    "El objetivo de transformar los datos es el de exponer mejor la estructura del problema a los algoritmos de modelado.\n",
    "\n",
    "**NECESIDAD:** \n",
    "- A veces los algoritmos pueden ofrecer mejores resultados sin procesamiento previo.\n",
    "- Lo ms normal:\n",
    "    - Crear muchas vistas y transformaciones diferentes de sus datos.\n",
    "    - Ejecutar un grupo de algoritmos en cada vista de su conjunto de datos.\n",
    "    \n",
    "La biblioteca scikit-learn proporciona dos formas estndar para transformar datos. Cada uno es til en diferentes circunstancias. Estas transformaciones se calculan de tal manera que se pueden usar con datos train y con cualquier muestra de datos que pueda tener en el futuro.\n",
    "\n",
    "Con scikit-learn trabajaremos 2 mtodos distintos:\n",
    "- **Ajuste y transformacin mltiple:**\n",
    "    - Llamamos a la funcin *fit()* para preparar los parmetros de la transformacin una vez en sus datos.\n",
    "    - Ms adelante, utilizamos utilizar la funcin *transform()* en los mismos datos para prepararla para el modelado y nuevamente en el conjunto de datos de prueba o validacin o en los nuevos datos que pueda ver en el futuro. \n",
    "- **Combinacin de ajuste y transformacin:**\n",
    "    - Utilizado para una sola tarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cargamos el dataset con Pandas que es muy til\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import set_printoptions\n",
    "\n",
    "fichero = './pima-indians-diabetes.data.csv'\n",
    "nombres = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(fichero, names=nombres)\n",
    "array = dataframe.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">**a) Re-escalar de datos (entre 0 y 1)**\n",
    "Cuando sus datos se componen de atributos con diferentes escalas, muchos algoritmos de aprendizaje automtico pueden beneficiarse de volver a escalar los atributos para que todos tengan la misma escala\n",
    "\n",
    ">Esto se conoce como normalizacin y los atributos a menudo se vuelven a escalar en el rango entre **0 y 1**:\n",
    "- Esto es til para los algoritmos de optimizacin utilizados en el ncleo de los algoritmos de aprendizaje automtico, como la pendiente de gradiente (gradient descent).\n",
    "- Tambin es til para algoritmos que ponderan entradas como regresin y redes neuronales y algoritmos que usan medidas de distancia como k-vecinos ms cercanos (k-Nearest Neighbors). \n",
    "\n",
    ">Puedes volver a escalar sus datos con scikit-learn usando la clase **MinMaxScaler**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# separamos matriz en componentes de entrada y salida\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "# resumimos los datos transformados\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">**b) Estandarizar los datos (0 mean, 1 stdev).**\n",
    "La estandarizacin es una tcnica til para transformar atributos con una distribucin gaussiana y medias diferenciales y desviaciones estndar a una distribucin gaussiana estndar con una media de 0 y una desviacin estndar de 1.\n",
    "\n",
    ">Es ms adecuada para tcnicas que asumen una distribucin gaussiana en las variables de entrada y trabajar mejor con datos re-escalados, como regresin lineal, regresin logstica y anlisis de discriminacin lineal.\n",
    "\n",
    ">Puede estandarizar los datos usando scikit-learn con la clase **StandardScaler**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# matriz separada en componentes de entrada y salida\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "\n",
    "# resumimos los datos transformados\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">**c) Normalizar datos (longitud de 1).**\n",
    "Normalizar en scikit-learn se refiere a cambiar la escala de cada **observacin (fila)** para que tenga una longitud de 1 (denominada norma de unidad o vector con la longitud de 1 en lgebra lineal).\n",
    "\n",
    ">Este mtodo de preprocesamiento puede ser til para **conjuntos de datos dispersos** (muchos ceros) con atributos de diferentes escalas cuando se usan algoritmos que ponderan valores de entrada como redes neuronales y algoritmos que usan medidas de distancia como k-Vecinos ms cercanos.\n",
    "\n",
    ">Podemos normalizar los datos en Python con scikit-learn usando la clase **Normalizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# separamos matriz en componentes de entrada y salida\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "\n",
    "# resumimos los datos transformados\n",
    "set_printoptions(precision=3)\n",
    "print(normalizedX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">**d) Binarizacin (0,1).**\n",
    "Podemos transformar sus datos utilizando un umbral binario.\n",
    "Todos los valores por encima del umbral estn marcados como 1 y todos iguales o por debajo estn marcados como 0. Esto se denomina binarizar sus datos o **poner un umbral** a sus datos:\n",
    "- Puede ser til cuando tienes probabilidades de que quieras hacer valores ntidos.\n",
    "- Tambin es til cuando se trata de ingeniera de caractersticas y desea agregar nuevas caractersticas que indiquen algo significativo.\n",
    "\n",
    "Puede crear nuevos atributos binarios en Python usando scikit-learn con la clase **Binarizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binaryX = binarizer.transform(X)\n",
    "\n",
    "# resumimos los datos transformados\n",
    "set_printoptions(precision=3)\n",
    "print(binaryX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 Seleccin de Caractersticas\n",
    "\n",
    "Las caractersticas de los datos utilizados para entrenar los modelos de aprendizaje automtico tienen mucha influencia en el rendimiento que darn.\n",
    "\n",
    "Las caractersticas irrelevantes o parcialmente relevantes pueden afectar negativamente el rendimiento del modelo. \n",
    "\n",
    "Veamos tcnicas de seleccin automtica de caractersticas que puede utilizar para preparar sus datos de aprendizaje automtico en Python con scikit-learn, destacando:\n",
    "1. **Seleccin univariante.**\n",
    "2. **Eliminacin de la caracterstica recursiva.**\n",
    "3. **Anlisis de componentes principales.**\n",
    "4. **Importancia de la caracterstica.**\n",
    "\n",
    "**OBJETIVO:** La seleccin de caractersticas es un proceso en el que selecciona automticamente aquellas caractersticas en nuestros datos que afectan ms a la variable o resultado de prediccin que buscamos.\n",
    "\n",
    "Tener caractersticas irrelevantes en los datos puede disminuir la precisin de muchos modelos, especialmente algoritmos lineales como regresin lineal y logstica.\n",
    "\n",
    "Tres beneficios de realizar la seleccin de caractersticas antes de modelar sus datos son:\n",
    "- Reduce el **OVERFITTING** (sobreajuste): menos datos redundantes significa reducir las probabilidades de **tomar decisiones basadas en el ruido**.\n",
    "- Mejora del **ACCURACY** (precisin): menos datos engaosos significa SIEMPRE una mejora del de la precisin del modelado.\n",
    "- Reduce el tiempo de **TRAINING** (entrenamiento): Menos datos significa que los algoritmos se entrenan ms rpido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Para Seleccin univariada\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "## Para PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "## Para RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "## Para importancia de la caracterstica\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 1. Seleccin univariante.\n",
    "Jugar probando con estadsticas nos ayuda a seleccionar aquellas caractersticas que tienen una relacin ms fuerte con la variable de salida. La biblioteca scikit-learn proporciona la clase SelectKBest que se puede usar con diferentes pruebas estadsticas para seleccionar un nmero especfico de funciones.\n",
    "\n",
    ">En el ejemplo utiliza la prueba estadstica de ji cuadrado (chi2) para caractersticas no negativas para seleccionar 4 de las mejores caractersticas del dataset Pima (diabetes en indios Pima).\n",
    "\n",
    ">**CONCLUSIN:** Puede ver los puntajes de cada atributo y los 4 atributos elegidos (aquellos con los puntajes ms altos): **plas, test, mass y age.** Obtenemos los nombres de los atributos elegidos asignando manualmente el ndice de las 4 puntuaciones ms altas al ndice de los nombres de atributos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.Extraccin de caractersticas con pruebas estadsticas univariadas \n",
    "\n",
    "##  (Chi-cuadrado para clasificacin)\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X, Y)\n",
    "\n",
    "# resumir puntuaciones\n",
    "set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "\n",
    "# resumen de las caractersticas seleccionadas\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 2. RFE (*Recursive Feature Elimination* - Eliminacin Recursiva de Caractersticas)\n",
    "La Eliminacin de caractersticas recursivas (o RFE) funciona eliminando atributos recursivamente y construyendo un modelo sobre aquellos atributos que permanecen. Utiliza la precisin del modelo para identificar qu atributos (y qu combinacin de atributos) contribuyen ms a la prediccin del atributo objetivo.\n",
    "\n",
    ">En el ejemplo utilizamos RFE con el algoritmo de regresin logstica para seleccionar las 3 funciones principales. La eleccin del algoritmo no importa demasiado siempre que sea hbil y consistente.\n",
    "\n",
    ">**CONCLUSIN:** Puedes ver que RFE eligi las 3 caractersticas principales como preg, mass y pedi. Estos estn marcados como TRUE en la **matriz de soporte** y marcados con una opcin 1 en la **matriz de clasificacin**. Tambin podemos asignar manualmente los ndices de caractersticas a los ndices de nombres de atributos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.Extraccin de caractersticas con RFE\n",
    "## modelo = LogisticRegression(solver='lbfgs')\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html\n",
    "modelo = SGDClassifier(max_iter=500,tol=1e-3,loss='log') #loss='modified_huber'\n",
    "rfe = RFE(modelo, 3)\n",
    "\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(nombres)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 3. PCA (*Principal Component Analysis*  Anlisis de Componente Principal)\n",
    "El anlisis de componentes principales (o PCA) utiliza el lgebra lineal para transformar el conjunto de datos en una forma comprimida. Se trata de una **tcnica reduccin de datos**. Una **propiedad** de PCA es que puede elegir el nmero de dimensiones o componentes principales en el resultado transformado. \n",
    "\n",
    ">En el ejemplo, usamos PCA y seleccionamos 3 componentes principales.\n",
    "\n",
    ">**CONCLUSIN:** Podemos ver que el conjunto de datos transformado (3 componentes principales) se parece poco a los datos de origen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3.Extraccin de caractersticas con PCA\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "\n",
    "# resumir componentes\n",
    "print(\"Varianza explicada: %s\" % fit.explained_variance_ratio_)\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 4. Importancia de Caractersticas\n",
    "Las bolsas de rboles de decisin (bagged decisin trees) como Random Forest y Extra Trees se pueden usar para estimar la importancia de las caractersticas.\n",
    "\n",
    ">En el ejemplo, construimos un clasicador *ExtraTreesClassifier* para el inicio de datos.\n",
    "\n",
    ">**CONCLUSIN:** Puede ver que se nos otorga una puntuacin de importancia para cada atributo en el que cuanto mayor sea sta, ms importante es el **atributo**. Las puntuaciones sugieren la importancia de los plas, age y mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4.Extraccin de importancia de las caractersticas\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "# 4.Evaluacin de los algoritmos\n",
    "\n",
    "##    4.1. Remuestreo (para evaluar el rendimiento)\n",
    "Esta etapa trata de resolver la siguiente necesidad: saber cmo se comportarn nuestros algoritmos con datos an no trabajados.\n",
    "\n",
    "Debemos usar nuestro algoritmo entrenado con nuevos datos (no utilizados para entrenar), con lo que la **EVALUACIN es una estimacin para comprobar como de buenas sern las predicciones que har en la prctica.** NO es una garanta de rendimiento.\n",
    "\n",
    "**PROBLEMA PLANTEADO**\n",
    "*Cul es el problema de usar un algoritmo de aprendizaje automtico en un dataset de entrenamiento y despus utilizar las predicciones de este mismo dataset para evaluar el rendimiento?* La respuesta es simple:\n",
    "\t\t**OVERFITTING o SOBREAJUSTE**\n",
    "Como el algoritmo se acuerda de todo lo que ha observado durante el entrenamiento y por tanto sabe la respuesta, no a nuevas preguntas, sino a las mismas de antes tendr una puntuacin perfecta con ellas. Pero cuando vaya a predecir dar resultados muy malos.\n",
    "\n",
    "Debemos usar nuestro algoritmo entrenado con nuevos datos (no utilizados para entrenar), con lo que la **EVALUACIN es una estimacin para comprobar como de buenas sern las predicciones que har en la prctica**. **NO** es una garanta de rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Mtodos de Evaluacin de algoritmos\n",
    "\n",
    "\"\"\"\n",
    "##Preparamos los entornos\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Una vez estimado el rendimiento de nuestro algoritmo, podemos volver a entrenar el algoritmo entrenado nal en todo el dataset de entrenamiento y prepararlo para el uso en operacin (en real).\n",
    "\n",
    "Vamos a revisar **4 tcnicas** que podemos usar para dividir nuestro conjunto de datos de entrenamiento y crear estimaciones tiles de rendimiento para nuestros algoritmos de aprendizaje automtico:\n",
    "1. Conjuntos de entrenamiento y test (particionado).\n",
    "2. Validacin cruzada (Cross-Validation) de k-folds.\n",
    "3. Validacin cruzada dejando fuera 1 particin (LOO).\n",
    "4. Validacin cruzada sobre particiones de Entrenamientos-Pruebas aleatorias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### Tcnica 1. Conjuntos de entrenamiento y test (Train-Test)\n",
    "\n",
    "Es el mtodo ms simple: utilizar **diferentes** conjuntos de datos de entrenamiento y test. Cogemos el *dataset* original y lo dividimos en 2:\n",
    "- **Entrenamos** el algoritmo en la primera parte y testeamos predicciones en la segunda parte.\n",
    "- **Evaluamos** las predicciones ltimas contra los resultados esperados. \n",
    "- **Tamao de la divisin:** Puede depender del tamao y las especificaciones del dataset, aunque es comn utilizar **(2/3  1/3) -> el 67%** de los datos para la entrenar y el 33% restante para las pruebas.\n",
    "\n",
    "**VENTAJAS:** Es muy rpido. Si hay millones de registros y hay pruebas slidas de que cada particin sigue representando el problema subyacente, es muy til cuando con otros mtodos tarda mucho tiempo en entrenarse.\n",
    "\n",
    "**INCONVENIENTES:** Mucha variacin, que hace que las diferencias en precisin entre el dataset de entrenamiento y el de test puedan ser significativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluar usando conjuntos de datos Train-Test con regresin logstica\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importante mantener la misma semilla para comparar entre distintas tcnicas.\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "# NOS FIJAMOS EN DETALLE - ver cmo se entrenan los datos para hacer un model.fit(), mediante train_test_split()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=150)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "results = model.score(X_test, Y_test)\n",
    "print(\"Precisin TT: %.3f%%\" % (result*100.0))\n",
    "\n",
    "## AVANZADO. Podis utilizar funciones que nos digan el timestamp antes y despus de la ejecucin, asignarlas a variables y \n",
    "##  restarlas para ver el tiempo de procesamiento de cada uno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### Tcnica 2. Validacin cruzada (Cross-Validation) de k-folds\n",
    "\n",
    "La **validacin cruzada (o Cross-Validation)** es un enfoque que puede utilizar para estimar el rendimiento de un algoritmo de AA con menos varianza que una nica divisin de conjunto de prueba de entrenamiento. \n",
    "- Dividimos el dataset en partes k (por ejemplo, k = 3, 5  10 para miles de registros). Cada divisin de los datos se llama **split**. \n",
    "- El algoritmo se entrena en k 1 splits sin usar 1 y se prueba en ese split sin usar.\n",
    "- Esto se repite para que cada split del dataset en algn momento sea el no usado.\n",
    "- Como resultado tenemos k diferentes valoraciones de rendimiento que podemos resumir utilizando **una media y una desviacin estndar**.\n",
    "\n",
    "La eleccin de k debe hacerse de forma que el tamao de cada particin de prueba (test) sea lo suficientemente grande como para ser una muestra razonable del problema, a la vez que se permiten suficientes iteraciones de la evaluacin del algoritmo (en Train-Test) que de buenos resultados con nuevos datos.\n",
    "\n",
    "**VENTAJAS:**\n",
    "Es ms preciso porque el algoritmo se entrena y evala varias veces con  diferentes datos.\n",
    "\n",
    "**INCONVENIENTES:** \n",
    "Depende de la seleccin correcta de las particiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Evaluar con Validacin Cruzada - Cross Validation\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=150)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Precisin VC: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### Tcnica 3. Validacin cruzada dejando fuera 1 particin (LOO)\n",
    "\n",
    "Se trata de una variacin en la que podemos configurar la validacin cruzada para que el tamao del split sea 1 (k se ajusta al nmero de observaciones del dataset) y se denomina validacin cruzada leave-one-out (LOO).\n",
    "\n",
    "**VENTAJA:** \n",
    "Como resultado nos proporciona una gran cantidad de medidas de rendimiento resumiendo el esfuerzo necesario para ofrecer estimaciones razonables de la precisin del modelo para nuevos datos.\n",
    "\n",
    "**INCONVENIENTE:** \n",
    "Depende de la seleccin correcta de las particiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluar con Validacin Cruzada dejando una particin - LOO\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loocv = LeaveOneOut()\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=150)\n",
    "results = cross_val_score(model, X, Y, cv=loocv)\n",
    "print(\"Precisin VC_LOO: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### Tcnica 4. Validacin cruzada sobre particiones de Train-Test aleatorias (*Shuffle Split*)\n",
    "\n",
    "Otra variacin en la **validacin cruzada de K-fold** es crear una divisin aleatoria de los datos como la divisin de Test-Train descrita anteriormente, pero **repetir el proceso de divisin y evaluacin del algoritmo varias veces**, como la validacin cruzada. \n",
    "\n",
    "**VENTAJA:**\n",
    "Combina la velocidad de usar una Test-Train con la reduccin en la varianza en el rendimiento estimado de la validacin cruzada de k-fold. Adems podemos repetir el proceso tantas veces como sea necesario para mejorar la precisin. \n",
    "\n",
    "**INCONVENIENTE:** \n",
    "Las repeticiones pueden incluir gran parte de los mismos datos en los split  de Train-Test de una ejecucin a otra, lo que introduce redundancia en la evaluacin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluacin mediante repeticin aleatoria de particiones Train-Test\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "n_splits = 10\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=150)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Precisin VC_ShuffleSplit: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### CONSEJOS DE REMUESTREO\n",
    "\n",
    "- Normalmente la **validacin cruzada con k-fold es el estndar de oro** para evaluar el rendimiento de un algoritmo de aprendizaje automtico en datos no tratados con k establecido en 3, 5 o 10.\n",
    "\n",
    "- El uso de un Train-Test es bueno para **mejorar la rapidez cuando se usa un algoritmo lento** y produce estimaciones de rendimiento con **menor sesgo** cuando se usan datasets grandes.\n",
    "\n",
    "- Tcnicas como la validacin cruzada dejando uno fuera (LOO) y las divisiones aleatorias repetidas (Shuffle-splits) sern aproximaciones tiles para intenta equilibrar la varianza en el **rendimiento estimado, la velocidad de entrenamiento del modelo y el tamao del *dataset**.\n",
    "\n",
    "- El mejor consejo es experimentar y encontrar una tcnica rpida para el problema y que produzca estimaciones razonables de rendimiento que me permita utilizarlas para tomar decisiones. En caso de duda, utilizad 10 veces la validacin cruzada.\n",
    "\n",
    "### MAL USO DE LA VALIDACIN CRUZADA\n",
    "\n",
    "- Usar la validacin cruzada para evaluar varios modelos, y slo indicando los resultados para el modelo con los mejores resultados.\n",
    "- Realizar un anlisis inicial para identificar las caractersticas ms informativas utilizando el dataset completo, si la seleccin de caracterstica o el ajuste del modelo lo requiere por el propio procedimiento de modelado, esto debe repetirse en cada conjunto de Train. Si se utiliza la VC para decidir qu caractersticas se van a utilizar, se deber realizar un proceso interno de VC para llevar a cabo la seleccin de caractersticas en cada conjunto de Train.\n",
    "- Permitir que algunos de los datos de entrenamiento est tambin incluido en el conjunto de Test, esto puede suceder debido a \"hermanamiento\" en el dataset, con lo que varias muestras exactamente idnticas o casi idnticas pueden estar presentes en el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## 4.2. Mtricas\n",
    "Las **mtricas** que elegimos para evaluar los algoritmos de aprendizaje automtico son muy importantes:\n",
    "- Influyen en cmo se mide y compara el rendimiento de los algoritmos de aprendizaje automtico. \n",
    "- Influyen en cmo evaluaremos la importancia de las diferentes caractersticas en los resultados y con ello la eleccin final de qu algoritmo elegir.\n",
    "\n",
    "Hay diferentes mtricas de evaluacin para tipos de problemas de aprendizaje automtico que tengan con **clasificacin** y con **regresin**:\n",
    "- Por ejemplo, el caso que utilizamos con el dataset de los indios Pima es un problema de clasificacin binaria en el que todas las variables de entrada son numricas.\n",
    "- En el dataset  del precio de las viviendas en Boston (Boston House Price) se trabaja con un problema de regresin en el que tambin todas las variables de entrada son numricas.\n",
    "\n",
    "En ambos casos evaluamos los mismos algoritmos, Regresin logstica para clasificacin y Regresin lineal para regresin. Se utiliza un de validacin cruzada de 10-fold para demostrar cada mtrica ya que es el escenario ms probable que utilizaremos: \n",
    "- Utilizaremos la funcin cross_validation.cross_val_score(): (http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html) utilizada para informar del rendimiento en cada cdigo de evaluacin. \n",
    "- Haremos uso de diferentes mtricas de puntuacin y todas las puntuaciones se detallan para que puedan clasificarse en orden ascendente (la puntuacin ms alta es la mejor). Algunas mtricas de evaluacin (como el error cuadrtico medio) son puntuaciones naturalmente descendentes (la puntuacin ms pequea es la mejor) y, por tanto, se notifican como negativas por la funcin de VC.\n",
    "\n",
    "### Mtricas de clasificacin y mtodos de conveniencia\n",
    "Los problemas de clasificacin son probablemente la tipologa ms comn de problemas de aprendizaje automtico y, por eso hay una gran cantidad de mtricas que se pueden usar para evaluar las predicciones de estos problemas.\n",
    "\n",
    "Trabajaremos 3 mtricas de clasificacin:\n",
    "1. **Precisin** (Accuracy).\n",
    "2. **Prdida logartmica** (Logarithmic Loss).\n",
    "3. **rea bajo la Curva ROC** (AUC ROC).\n",
    "\n",
    "Usaremos 2 mtodos de conveniencia:\n",
    "4. **Matriz de confusin**.\n",
    "5. **Informe de clasicacin**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# VC-Precisin de clasificacin \n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NOS INTRODUCIMOS EN LAS 3 MTRICAS\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Mtricas\n",
    "> ### 1. Precisin de clasificacin:\n",
    "N de predicciones correctas hechas como proporcin de todas las predicciones hechas:\n",
    "- Es la mtrica de evaluacin ms comn y ms mal utilizada para problemas de clasificacin. \n",
    "- Realmente slo es adecuada con un nmero igual de observaciones en cada clase (casi nunca se da) y que todas las predicciones y errores de prediccin son igualmente importantes (tampoco se suele dar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Asignar a la variable scoring se valor que le corresponde para lograr precisin o accuracy\n",
    "scoring = 'accuracy'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Precisin: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 2. Prdida logartmica (LogLoss): \n",
    "Mtrica de rendimiento para evaluar las predicciones de probabilidades de pertenencia a una clase determinada. \n",
    "- La probabilidad escalar entre 0 y 1 se puede ver como una medida de confianza para una prediccin de un algoritmo. \n",
    "- Las predicciones que son correctas o incorrectas son recompensadas o castigadas proporcionalmente a la confianza de la prediccin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Asignad a la variable scoring se valor que le corresponde para lograr logloss\n",
    "scoring = 'neg_log_loss'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Logloss: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 3. rea bajo la curva ROC:\n",
    "Mtrica de rendimiento para problemas de clasificacin **binaria**. El AUC representa la capacidad de un modelo para discriminar entre clases positivas y negativas.\n",
    "- Un rea de 1.0 representa un modelo que hizo perfectamente todas las predicciones. Un rea de 0.5 representa un modelo que es tan bueno como aleatorio. \n",
    "- ROC se puede dividir en **sensibilidad** y **especificidad**. Un problema de clasificacin binaria es realmente un intercambio entre sensibilidad y especificidad:\n",
    "    - La **sensibilidad** es el llamado **recuerdo** o la verdadera tasa positiva: N de instancias de la clase positiva (primera) que realmente predijo correctamente.\n",
    "    - La **especificidad** tambin se llama verdadera tasa negativa: N de instancias de la clase negativa (segunda) que en realidad se predijeron correctamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Asignad a la variable scoring se valor que le corresponde para lograr curva ROC\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std())*100)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "probs = model.predict_proba(X_test)\n",
    "# mantenemos las probabilidades de salidas 1\n",
    "probs = probs[:, 1]\n",
    "# Calcular AUC\n",
    "auc = roc_auc_score(Y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# Calcular la curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, probs)\n",
    "\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "# PRIMER PASO. NOS INTRODUCIMOS EN LOS DOS MTODOS - entrenamos los datos para hacer un model.fit() \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Mtodos de conveniencia\n",
    "\n",
    "> ### 4. Matriz de confusin: \n",
    "Es una presentacin prctica de la precisin de un modelo con **2 o ms clases**.\n",
    "- La tabla presenta **predicciones** sobre el eje x y **resultados de precisin** en el y. Las celdas de la tabla son el nmero de predicciones realizadas por un algoritmo de aprendizaje automtico. \n",
    "- Por ejemplo, un algoritmo de aprendizaje automtico puede predecir 0  1 y cada prediccin puede haber sido 0  1:\n",
    "    - Las predicciones para 0 que en realidad eran 0 aparecen en la celda para prediccin = 0 y real = 0,\n",
    "    - mientras que las predicciones para 0 que fueron en realidad 1 aparece en la celda para prediccin = 0 y real = 1 (y as sucesivamente).\n",
    "- La mayora de las precisiones deberan caer en la diagonal que representan las predicciones correctas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# SEGUNDO PASO. Asignamos a predicted el valor de X_test y creamos la matriz de confusin con el mtodo confusion_matriz\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 5. Informe de clasificacin: \n",
    "La biblioteca de scikit-learn proporciona un informe de adecuacin cuando trabajamos en problemas de clasificacin que nos proporciona una idea inicial de la precisin de un modelo utilizando una serie de medidas.\n",
    "- La funcin *ranking_report()* muestra la precisin, el recuerdo, el F1-score y el soporte para cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# TERCER PASO. Asignamos a predicted el valor de X_test y creamos el informe con classification_report\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.3. Test Puntual\n",
    "El test puntual es una forma de descubrir qu algoritmos funcionan bien en un problema de aprendizaje automtico. \n",
    "- Como no sabemos de antemano cul ser mejor, debemos probar varios mtodos y centrarnos en aquellos que demuestran ser ms precisos.\n",
    "- Debe usar el mtodo de prueba y error para descubrir una lista breve de algoritmos que funcionan bien en su problema, que luego puede duplicar y ajustar ms. \n",
    "- Se trata de ajustarnos a nuestro dataset para escoger el mejor algoritmo:\n",
    "    - Probar una mezcla de representaciones de algoritmos (rboles, instancias).\n",
    "    - Probar una mezcla de algoritmos de aprendizaje.\n",
    "    - Probar una mezcla de tipos de modelos (funciones lineales-no lineales o paramtricas-no paramtricas).\n",
    "    \n",
    "En un **problema de clasificacin** nos interesa saber:\n",
    "1. Cmo hacer test de los algoritmos de aprendizaje automtico.\n",
    "2. Cmo hacer test de algoritmos de clasificacin lineal. Veamos **2**:\n",
    "    1. Regresin logstica.\n",
    "    2. Anlisis Lineal Discriminante (LDA).\n",
    "3. Cmo hacer test de algoritmos de clasificacin no lineal. Veamos **4**:\n",
    "    1. k-Nearest Neighbors (o K-Vecinos ms cercanos).\n",
    "    2. Nave Bayes.\n",
    "    3. rboles de clasificacin y regresin.\n",
    "    4. Mquinas de Vector Soporte o Support Vector Machines (SVM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### I.Algoritmos Lineales de clasificacin\n",
    "> ### 1. Regresin Logstica\n",
    "- La regresin logstica asume una distribucin gaussiana para las variables de entrada numricas y puede modelar problemas de clasificacin binaria. \n",
    "- Puedes construir un modelo de regresin logstica utilizando la clase *LogisticRegression()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Para un ejemplo de clasificacin vamos a hacer chequeos puntuales que nos \n",
    "permitan saber cules de nuestros algoritmos se van a comportar mejor a la \n",
    "hora de resolver nuestro problema\n",
    "\"\"\"\n",
    "# Proceso comn a todos los escenarios\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.Clasificacin mediante Regresin Logstica\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Regresin logstica: \" + str(results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 2. Anlisis Lineal Discriminante (LDA):\n",
    "- El anlisis discriminante lineal o LDA es una tcnica estadstica para la clasificacin binaria y multiclase. Tambin asume una distribucin gaussiana para las variables de entrada numricas. \n",
    "- Puedes construir un modelo de LDA usando la clase *LinearDiscriminantAnalysis()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.Clasificacin con LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"LDA: \" + str(results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### II.Algoritmos No Lineales de clasificacin\n",
    ">### 1. k-Nearest Neighbors (o K-Vecinos ms cercanos):\n",
    "- El algoritmo KNN utiliza una mtrica de distancia para encontrar las k-instancias ms similares en los datos de entrenamiento de una nueva instancia y toma el resultado promedio de los vecinos como la prediccin. \n",
    "- Para construir el modelo KNN usa la clase *KNeighborsClassifier()*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Clasificacin No Lineal KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"KNN: \" + str(results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">### 2. Naive Bayes:\n",
    "- Naive Bayes calcula la **probabilidad** de cada clase y la **probabilidad condicional** de cada clase dado cada valor de entrada. Estas probabilidades se estiman para datos nuevos y se multiplican juntas, asumiendo que son todas independientes (un supuesto simple o ingenuo). Cuando se trabaja con datos de valor real, se supone que una distribucin gaussiana para estimar fcilmente las probabilidades de las variables de entrada utilizando la funcin de densidad de probabilidad gaussiana (**GPDF**). \n",
    "- Para construir un modelo Naive Bayes usa la clase *GaussianNB()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Clasificacin NL Naive Bayes Gaussiana\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Naive Bayes: \" + str(results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 3. rboles de clasificacin y regresin:\n",
    "- Los rboles de clasificacin y regresin (**CART** o simplemente rboles de decisin) construyen un rbol binario a partir de los datos de entrenamiento. Los puntos de divisin se eligen de forma rpida al evaluar cada atributo y cada valor de cada atributo en los datos de entrenamiento para minimizar una funcin de coste (como el ndice de Gini).\n",
    "- Puedes construir un modelo CART usando la clase *DecisionTreeClassifier()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3.Clasificacin No Lineal CART (Classification And Regression Trees)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"CART: \" + str(results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> ### 4. Mquinas de Vector Soporte o Support Vector Machines (SVM):\n",
    "- Las SVM buscan la lnea que mejor separa dos clases. Las instancias de datos que estn ms cerca de esa lnea se denominan **vectores de soporte** e influyen en la ubicacin de la lnea. SVM tambin soportar **mltiples clases**. A travs del parmetro *kernel* podemos utilizar diferentes funciones del kernel. Por defecto, se utiliza una potente Funcin de Base Radial.\n",
    "- Puedes construir un modelo SVM usando la clase *SVC()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4.Clasificacin No Lineal Mquina de Vector Soporte - SVM \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(gamma='scale') #podemos usar 'auto' como gamma\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"SVC: \" + str(results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.4. Comparacin y seleccin de modelos\n",
    "\n",
    "Es importante comparar constantemente el rendimiento de los diferentes algoritmos de aprendizaje automtico segn los utilizamos. \n",
    "\n",
    "Vamos a generar un marco de prueba que nos sirva como plantilla para los problemas de aprendizaje automtico que tengamos, e incluso ir agregando ms algoritmos diferentes que me sirvan para comparar. El objetivo:\n",
    "1. Saber cmo formular un experimento para comparar directamente los algoritmos de aprendizaje automtico.\n",
    "2. Tener una plantilla reutilizable para evaluar el rendimiento de diferentes algoritmos en un conjunto de datos dado.\n",
    "3. Saber cmo informar y visualizar los resultados cuando se compara el rendimiento del algoritmo.\n",
    "\n",
    "Cuando trabajas en un proyecto de aprendizaje automtico (ML), sueles acabar con varios buenos modelos para elegir. Cada uno tendr **diferentes caractersticas de rendimiento**. \n",
    "- Con el re-muestreo con mtodos como la validacin cruzada, podemos obtener una estimacin de la precisin de cada modelo en datos nuevos. Con estas estimaciones tienes que ser capz de elegir 1  2 de los mejores modelos del conjunto de modelos que hayamos creado.\n",
    "\n",
    "Cuando tenemos un conjunto de datos nuevo, es una buena idea visualizar los datos utilizando diferentes tcnicas para tener diferentes perspectivas de los datos. Esta misma idea se aplica a la seleccin del model):\n",
    "- Usaremos una serie de mtodos diferentes para ver la precisin estimada de los algoritmos de ML y elegir uno o dos algoritmos para nalizar. \n",
    "- Una forma de hacerlo es usar mtodos de visualizacin que muestren la precisin media, varianza y otras propiedades de la distribucin de precisiones del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compararemos los siguientes algoritmos\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Preparamos los modelos incluyendo una matriz o array con todas las soluciones\n",
    "modelos = []\n",
    "modelos.append(('LR', LogisticRegression(solver='lbfgs', max_iter=500)))\n",
    "modelos.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "modelos.append(('KNN', KNeighborsClassifier()))\n",
    "modelos.append(('CART', DecisionTreeClassifier()))\n",
    "modelos.append(('NB', GaussianNB()))\n",
    "modelos.append(('SVM', SVC(gamma='scale')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cargamos el dataset para poder ejecutar slo este apartado.\n",
    "filename = './pima-indians-diabetes.data.csv'\n",
    "nombres = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=nombres)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Nos generamos una plantilla en bucle con la que evaluamos cada modelo por turnos\n",
    "resultados = []\n",
    "nombres = []\n",
    "scoring = 'accuracy'\n",
    "for nombre, modelo in modelos:\n",
    "\tkfold = KFold(n_splits=10, random_state=7)\n",
    "\tcv_results = cross_val_score(modelo, X, Y, cv=kfold, scoring=scoring)\n",
    "\tresultados.append(cv_results)\n",
    "\tnombres.append(nombre)\n",
    "\tmsg = \"%s: %f (%f)\" % (nombre, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Boxplot de comparacin de algoritmos\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Comparacin de los algoritmos')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(resultados)\n",
    "ax.set_xticklabels(nombres)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "# 5.Mejorar la precisin del modelo\n",
    "## 5.1. Ensembles (Conjuntos)\n",
    "\n",
    "Los **3 mtodos** ms populares para combinar las predicciones de diferentes modelos son:\n",
    "- **Boosting**. Construye mltiples modelos (normalmente del mismo tipo), cada uno de los cuales aprende a arreglar los errores de prediccin de un modelo anterior en la secuencia de modelos.\n",
    "- **Bagging**. Construye mltiples modelos (normalmente del mismo tipo) a partir de diferentes submuestras del conjunto de datos de entrenamiento.\n",
    "- **Voting (Votacin)**. Construye mltiples modelos (generalmente de diferentes tipos) y estadsticas simples (como la media) se utiliza para combinar predicciones.\n",
    "\n",
    "Para revisarlos y utilizando el dataset, cada algoritmo de ensemble se trabaja utilizando una validacin cruzada de 10-folds y la mtrica de rendimiento de precisin (accuracy) de la clasicacin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">### 1. Boosting.\n",
    "- Los algoritmos de **boosting** crean una secuencia de modelos que intentan corregir los errores de los modelos anteriores a ellos en la secuencia preparada. Una vez creados, los modelos hacen predicciones que pueden ser ponderadas por su precisin demostrada y los resultados se combinan para crear una prediccin de salida final.\n",
    "- Lo veremos a continuacin, pero a diferencia del **bagging**, en el**boosting**no se crean versiones del conjunto de entrenamiento, sino que se trabaja siempre con el conjunto completo de entrada, y se manipulan los pesos de los datos para generar modelos distintos. La idea es que en cada iteracin se incremente el peso de los objetos mal clasificados por el predictor en esa iteracin, por lo que en la construccin del siguiente predictor estos objetos sern ms importantes y ser ms probable clasificarlos bien.\n",
    "- Los 2 algoritmos de boosting ms comunes son:\n",
    "    1. **AdaBoost**. Fue quizs el primer algoritmo ensemble con ms xito. \n",
    "        - Por lo general, funciona ponderando las instancias en el conjunto de datos por lo fcil o difcil que es clasificarlas, lo que permite que el algoritmo les preste menos atencin en la construccin de los modelos posteriores.\n",
    "        - Puede construir un modelo de AdaBoost para la clasificacin utilizando la clase *AdaBoostClassifier* (en el ejemplo usaremos  30 rboles de decisin en secuencia).\n",
    "    2. **Stochastic Gradient Boosting** (Aumento de Gradiente Estocstico). \n",
    "        - El SGB (tambin llamado *Gradient Boosting Machine*) es una de las tcnicas de ensemble ms sofisticadas. Tambin es una tcnica que est demostrando ser quizs una de las mejores disponibles para mejorar el rendimiento a travs de conjuntos. \n",
    "        - Utilizaremos para clasificacin la clase *GradientBoostingClassifier*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trabajamos con los 3 mtodos ms populares para combinar las predicciones:\n",
    "1. Boosting. \n",
    "2. Bagging.\n",
    "3. Voting.\n",
    "\"\"\"\n",
    "#Importaciones generales para todos los ensembles\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Carga de datos y generacin de los kfold\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "seed=7\n",
    "kfold = KFold(n_splits=10, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Boosting\n",
    "    1.AdaBoost\n",
    "    2.SGB-Stochastic Gradient Boosting\n",
    "\"\"\"\n",
    "# 1.1.AdaBoost para clasificacin (30 rboles)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "num_trees = 30\n",
    "modelo = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "resultados = cross_val_score(modelo, X, Y, cv=kfold)\n",
    "print(\"AdaBoost: \" + str(resultados.mean()))\n",
    "\n",
    "# 1.2.SGB-Stochastic Gradient Boosting para clasificacin (100 rboles)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "num_trees = 100\n",
    "modelo = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
    "resultados = cross_val_score(modelo, X, Y, cv=kfold)\n",
    "print(\"SGB: \" + str(resultados.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">### 2. Bagging o Embolsado.\n",
    "Bagging o embolsado. Se llama tambin Agregacin (o Bagging) de Bootstrap e implica tomar mltiples muestras del conjunto de datos de entrenamiento (con reemplazo) y entrenar un modelo para cada muestra. La prediccin nal es la media de las predicciones de cada uno de los submodelos.\n",
    "Vamos a ver 3 modelos de Bagging, aunque existen ms:\n",
    "1. **rboles de decisin embolsados o Bagged Decission Trees**: \n",
    "El bagging se realiza mejor con algoritmos que tienen una varianza alta. Un ejemplo tpico son los rboles de decisin, a menudo construidos sin poda. Usaremos *BaggingClassifier()* con el algoritmo de rboles de clasificacin y regresin (*DecisionTreeClassifier*).\n",
    "2. **Bosque Aleatorio o Random Forest**: \n",
    "**Random Forests** es una extensin de los *Bagged Decission Trees*. Las muestras del conjunto de datos de entrenamiento se toman con reemplazo, pero los rboles se construyen de una manera que reduce la correlacin entre las clases individuales. As, en vez de elegir el mejor punto de divisin en la construccin de cada rbol, solo se considera un subconjunto aleatorio de caractersticas para cada divisin. Usaremos *RandomForestClassifier()*.\n",
    "3. **rboles adicionales o Extra Trees**: \n",
    "Es otra variacin de **bagging** en la que los rboles aleatorios se construyen a partir de muestras del conjunto de datos de entrenamiento. Para crear el modelo de rboles adicionales para la clasificacin usamos la clase *ExtraTreesClassifier()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2. Bagging (todos con 100 rboles):\n",
    "    1.Bagged Decision Trees\n",
    "    2.Random Forest\n",
    "    3.Extra Trees\n",
    "\"\"\"\n",
    "# 2.1.Bagged Decision Trees para clasificacin\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "num_trees = 100\n",
    "cart = DecisionTreeClassifier()\n",
    "modelo = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n",
    "resultados = cross_val_score(modelo, X, Y, cv=kfold)\n",
    "print(\"Bagged Decision Trees: \" + str(resultados.mean()))\n",
    "\n",
    "# 2.2.Random Forest para clasificacin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "max_features = 3\n",
    "\n",
    "modelo = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "resultados = cross_val_score(modelo, X, Y, cv=kfold)\n",
    "print(\"Random Forest: \" + str(resultados.mean()))\n",
    "\n",
    "# Extra Trees para clasificacin\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "max_features = 7\n",
    "\n",
    "modelo = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "resultados = cross_val_score(modelo, X, Y, cv=kfold)\n",
    "print(\"Extra Trees: \" + str(resultados.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">### 3. Voting o Votacin.\n",
    "Es una de las formas ms simples de combinar las predicciones de mltiples algoritmos de aprendizaje automtico:\n",
    "- Funciona creando primero 2 o ms modelos independientes a partir de su conjunto de datos de entrenamiento. Luego se puede usar un clasificador de Voting para encapsular los modelos y promediar las predicciones de los submodelos para cuando tenga que hacer predicciones para nuevos datos. \n",
    "- Las predicciones de los submodelos pueden ponderarse, pero es difcil especificar los pesos para los clasicadores de forma manual o incluso heurstica.\n",
    "- Los mtodos ms avanzados pueden aprender cmo ponderar mejor las predicciones de los submodelos; esto se denomina apilamiento o *stacking* (agregacin apilada) y actualmente no se proporciona en scikit-learn.\n",
    "- Usaremos la clase *VotingClassifier()* para crear modelos de Voting. Haremos un *ensemble* de las predicciones de regresin logstica, CART y SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3. Voting.\n",
    "\"\"\"\n",
    "# Voting Ensemble para Clasificacin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Creamos los submodelos\n",
    "estimadores = []\n",
    "modelo1 = LogisticRegression()\n",
    "estimadores.append(('logistic', modelo1))\n",
    "modelo2 = DecisionTreeClassifier()\n",
    "estimadores.append(('cart', modelo2))\n",
    "modelo3 = SVC()\n",
    "estimadores.append(('svm', modelo3))\n",
    "\n",
    "# Creamos el modelo ensemble\n",
    "ensemble = VotingClassifier(estimadores)\n",
    "resultados = cross_val_score(ensemble, X, Y, cv=kfold)\n",
    "print(\"Voting Ensemble: \"+ str(resultados.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5.2.Tuning\n",
    "- Normalmente **la validacin cruzada con k-fold es el estndar de oro** para evaluar el rendimiento de un algoritmo de aprendizaje automtico en datos no tratados con k establecido en 3, 5 o 10.\n",
    "- El uso de un Train-Test es bueno para **mejorar la rapidez cuando se usa un algoritmo lento** y produce estimaciones de rendimiento con **menor sesgo** cuando se usan datasets grandes.\n",
    "- Tcnicas como la validacin cruzada dejando uno fuera (LOO) y las divisiones aleatorias repetidas (Shuffle-splits) sern aproximaciones tiles para intenta equilibrar la varianza en el **rendimiento estimado, la velocidad de entrenamiento del modelo y el tamao del *dataset**.\n",
    "- El mejor consejo es experimentar y encontrar una tcnica rpida para el problema y que produzca estimaciones razonables de rendimiento que me permita utilizarlas para tomar decisiones. En caso de duda, utilizad **10 veces la validacin cruzada**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Voting Ensemble para Clasificacin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Creamos los submodelos\n",
    "estimadores = []\n",
    "modelo1 = LogisticRegression(solver='liblinear')\n",
    "estimadores.append(('logistic', modelo1))\n",
    "modelo2 = DecisionTreeClassifier()\n",
    "estimadores.append(('cart', modelo2))\n",
    "modelo3 = SVC()\n",
    "estimadores.append(('svm', modelo3))\n",
    "\n",
    "# Creamos el modelo ensemble\n",
    "ensemble = VotingClassifier(estimadores)\n",
    "resultados = cross_val_score(ensemble, X, Y, cv=kfold)\n",
    "print(\"Voting Ensemble: \"+ str(resultados.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "# 6.Cerrar y guardar el modelo\n",
    "\n",
    "El hecho de encontrar un modelo de aprendizaje automtico y afinarlo para ser lo ms preciso posible no es la ltima etapa del proyecto.\n",
    "\n",
    "Una vez conseguido lo anterior, guardaremos nuestro modelo y podremos cargarlo a posteriori para hacer predicciones. Ahora nos quedan 2 posibles mtodos:\n",
    "- Cmo usar **Pickle** para serializar y de-serializar modelos de aprendizaje automtico. \n",
    "- Cmo usar **Joblib** para serializar y de-serializar modelos de aprendizaje automtico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6.1.Pickle\n",
    "**Pickle**  es la forma estndar de serializar objetos en Python. \n",
    "- **Guardar**: Importaremos pickle para serializar sus algoritmos de aprendizaje automtico y guardar el formato serializado en un archivo (mediante dump()). Se genera un fichero nombreModelo.sav\n",
    "- **Cargar**: En cualquier momento podemos cargar este archivo para de-serializar el modelo (mediante load()) y usarlo para hacer nuevas predicciones. \n",
    "\n",
    "En el caso de los datos de diabetes de los indios Pima, una vez entrenado el modelo de regresin logstica, guardaremos el modelo en un archivo (**modelo_finalizado.sav**) y cuando recibamos nuevos conjuntos de datos podremos hacer predicciones con l."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "\n",
    "# Ajustar el modelo al 33%\n",
    "modelo = LogisticRegression(solver='liblinear')\n",
    "modelo.fit(X_train, Y_train)\n",
    "\n",
    "# Guardamos el modelo al disco\n",
    "fichero_modeloPickel = 'modelo_finalizado_pickel.sav'\n",
    "dump(modelo, open(fichero_modeloPickel, 'wb'))\n",
    "\n",
    "#Cuando lo vaya a recuperar en otro momento\n",
    "\n",
    "# Cargamos el modelo del disco\n",
    "modelo_cargado = load(open(fichero_modeloPickel, 'rb'))\n",
    "resultado = modelo_cargado.score(X_test, Y_test)\n",
    "print(\"Resultado: \" + str(resultado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6.2.Joblib\n",
    "La biblioteca Joblib pertenece al ecosistema SciPy y proporciona utilidades para hacer pipelines de jobs Python. Se ayuda de estructuras de datos Numpy para guardar y cargar objetos Python, de forma muy eficiente.\n",
    "\n",
    "Con algunos algoritmos de aprendizaje automtico que requieren muchos parmetros o almacenan el conjunto de datos completo (por ejemplo, K-nn) es muy til.\n",
    "\n",
    "Al igual que en el ejemplo anterior, lo guardaremos en el fichero .sav, y una vez recuperado, lo ejecutamos y mostrar una estimacin de la precisin en ese conjunto de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import dump\n",
    "from sklearn.externals.joblib import load\n",
    "\n",
    "# Guardamos el modelo al disco\n",
    "fichero_modeloJoblib = 'modelo_finalizado_joblib.sav'\n",
    "dump(modelo, fichero_modeloJoblib)\n",
    "\n",
    "#Cuando lo vaya a recuperar en otro momento\n",
    "\n",
    "# Cargamos el modelo del disco\n",
    "modelo_cargado = load(fichero_modeloJoblib)\n",
    "resultado = modelo_cargado.score(X_test, Y_test)\n",
    "print(\"Resultado: \" + str(resultado))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "## Conclusiones\n",
    "Consideraciones importantes a la hora de nalizar nuestros modelos:\n",
    "- **Versin de Python**. Anotad la versin de Python. Casi seguro que necesitaremos la misma versin (y quizs menor) de Python con la que serializamos el modelo, para hacer el proceso de carga y deserializacin.\n",
    "- **Versiones de la librera**. La versin de todas las libreras principales utilizadas en el proyecto casi seguro que debern ser las mismas cuando deserializa un modelo guardado (no solo usaremos NumPy y scikit-learn).\n",
    "- **Serializacin manual**. Es posible que desee generar manualmente los parmetros de su modelo aprendido para que pueda usarlos directamente en scikit-learn (o la plataforma que uses en el futuro). \n",
    "    - A menudo, las tcnicas utilizadas internamente por los algoritmos de aprendizaje automtico para hacer predicciones son mucho ms simples que las que se usan para aprender los parmetros y pueden ser fciles de implementar en cdigo personalizado ms fcil de controlar por nosotros.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}