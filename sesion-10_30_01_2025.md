Código FUNDAE: CONVERGENCIA

* Entrega borrador 2 proyecto: ya está subida a la plataforma el enunciado correcto.

Criterios de calificación:

* Criterio 1 (15%): Carga del dataset, limpieza de datos, conversiones de tipos, transformaciones sobre columnas por ejemplo aquellas que tengan número con texto decidir qué hacer con ellas. Transformaciones a nivel de pandas con el objetivo de corregir los datos por ejemplo: columnas que tienen número y texto como podría ser superficie en metros cuadrados: 80 m^2.

* Criterio 2 (30%): EDAs univariante, bivariante, multivariante para entender los datos, analizarlos también estandarizados. Visualizaciones con matplotlib, seaborn, plotly. Se puede probar a aplicar un StandardScaler sobre algunas columnas para poder comparar sus histogramas superpuestos por ejemplo. Imputers como por ejemplo SimpleImputer, KNNImputer o IterativeImputer para imputar valores nulos. Correlaciones. Pairplot o scatterplots o relplots con parámetros hue, col, row. Univariantes, bivariantes, multivariantes. Analizar la asimetría skew, curtosis, se puede corregir en el criterio 3 de preprocesados.

* Criterio 3 (20%): Preprocesados: encoding, escalado, creación de nuevas características.
    * train_test_split: X y se dividen X_train, y_train y en X_test y_test Para que no haya fuga de datos o data leakage a la hora de entrenar.
    * pd.get_dummies para codificar categóricas a numéricas o usar la clase OneHotEncoder de ScikitLearn
    * Escalado: MinMaxScaler o RobustScaler (ver antes y después para ver si mejora)
    * Transformar la distribución de datos sesgados en la X
        * Comprobar asimetría: X.skew(), X.kurt()
        * Intentar mejorarla con: QuantileTransformer o PowerTransformer para intentar hacerla gaussiana
        * **Opcional**: quien quiera puede transformar la distribución del precio y luego después de predecir, hacer la inversa de la transformación utilizando un método inverse_transform con el Transformer utilizado
    * Discretización o Binarización (Opcional no hace falta), ejemplo:
        * Precio discretizar en 'barato', 'medio', 'caro', 'muy caro'.
        * Edad 0 - 100 la binarizamos en 'mayor de edad' y 'no mayor de edad' en función de si tiene 18 años o más.
        * KBinsDiscretizer y Binarizer
    * Opcional: filtrar outliers manualmente con técnica Valle Tukey IQR, o con IsolationForest
    * PCA: (Opcional) si tenemos muchas columnas después de hacer un encoding, podemos aplicar un PCA para reducir el numero de columnas manteniendo la máxima varianza o información posible.
    * Crear columnas (Opcional): estudiando los datos ver si se puede inferir algún tipo de información que se pueda crear como nueva columna.
        * Por ejemplo en titanic, se puede crear una columna family_size que sea resultado de: 1 + SibSp + Parch
        * Por ejemplo en diamonds, se puede crear una columna volume que sea resultado de: x + y + z


* Criterio 4 (35 %): Modelados: usar modelos de scikit learn y tensorflow para realizar una regresión sobre la columna Price, y una clasificación binaria sobre la columna balcony (si tiene terraza o no). Comparativa de resultados con los modelos.
    * Regresión sobre la columna PRICE:
        * Algoritmos: LinearRegression, KNeighborsRegressor, DecisionTreeRegressor, SVR, RandomForestRegressor, GradientBoostingRegressor. Sobre la columna Price. Red neuronal de regresión con TensorFlow.
        * Métricas: R2, MAE, RMSE, MAPE...
    * Clasificación binaria sobre la columna BALCONY: 
        * Algoritmos: LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier, SVC, RandomForestClassifier, GradientBoostingClassifier 
        * Métricas: Accuracy, Precision, Recall, F1, AUC
    * validación cruzada: cross_validate() en scikit learn, en vez de obtener un R2, obtienes 5 veces un R2, de esa forma entrenas y testeas 5 veces, así calculas la media de ese R2 y tienes un R2 más realista o fiable o cercano a la realidad. Habitualmente se hace KFold = 5 iteraciones o 10 iteraciones. LeaveOneOut está bien cuando tenemos un dataset pequeño con pocas filas.
    * La validación cruzada devuelve un diccionario de resultados que podemos usar para crear un dataframe y comparar los resultados con group by y sort_values descendente, opcionalmente mostrar boxplot comparando métricas de los algoritmos.

Formato: proyecto_nombre_apellido.ipynb


Data leakage: 
    * si usamos un StandardScaler (X - media / std)
    * si se aplica sobre todo el dataset antes de particionar lo que ocurre es que los datos test están afectando al cálculo de la media y std
    * usas ese scaler "influenciado" por los datos de test lo usas en datos de Train que ve el modelo.
    * el modelo ve datos "influenciados" por test.
    * hincharía las métricas de predicción de y_test, es decir, que el modelo puntuaría más álto gracias a que los datos fueron transformados teniendo en cuenta datos de test.
    * Para que no haya fuga de datos el modelo no debe ver nada relacionado con test.

* Outliers:
    * Cálculo IQR = Q3 - Q1
    * Filtro inferior: Q1 - 1.5 * IQR
    * Filtro superior: Q3 + 1.5 * IQR
    * En distribuciones normales: IQR ~ 1.35 veces la desviación estandar (1,35 * σ)
    * En Scikit se pueden detectar los outliers utilizando algoritmos (aprendizaje no supervisado): IsolationForest


-- 
* Clasificación binaria
* Clasificación multiclase
