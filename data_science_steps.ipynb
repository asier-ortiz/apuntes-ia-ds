{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Metodología y pasos para problemas de ciencia de datos\n",
    "\n",
    "* 1. Carga de datos y exploración de datos\n",
    "\n",
    "    * Carga de datos\n",
    "    * Ver las columnas del DataFrame (df.info(), df.describe()...)\n",
    "    * Corrección de errores en datos (si los hay)\n",
    "    * Cambios en tipos de datos con astype\n",
    "\n",
    "* 2. EDA con matplotlib, seaborn, plotly, profiling tools\n",
    "\n",
    "    * Univariante: histogramas, boxplots\n",
    "    * Bivariante: scatterplot\n",
    "    * Multivariante: heatmap, relplot (si se necesita, para correlaciones, PCA visual en 2D y 3D)\n",
    "    * Objetivo: Entender los datos para tomar decisiones sobre preprocesamiento y modelado.\n",
    "\n",
    "* 3. Definir el objetivo del modelado\n",
    "\n",
    "    * Identificar columna target (\"y\") y analizar su tipo:\n",
    "        * Numérica continua ➝ Regresión\n",
    "        * Categórica discreta ➝ Clasificación\n",
    "    * Separar datos en X (features) e Y (target)\n",
    "    * Objetivo: Saber qué queremos predecir y cómo estructurar el problema.\n",
    "\n",
    "\n",
    "* 4. Particionamiento/División de los datos para modelado\n",
    "    * Separación en train y test (train_test_split)\n",
    "    * Objetivo: Evitar data leakage (fuga de datos) y evaluar correctamente el modelo.\n",
    "\n",
    "\n",
    "* 5. Preprocesados (donde más tiempo se invierte)\n",
    "    * Manejo de valores nulos y outliers\n",
    "    * Codificación de variables categóricas (one-hot, label encoding, etc.)\n",
    "    * Estandarización, escalado (si es necesario)\n",
    "    * Eliminar sesgos mediante transformación de distribuciones\n",
    "    * EDA antes y después del preprocesamiento\n",
    "    * Cuidado: usar fit_transform sobre datos X_train y transform sobre datos X_test\n",
    "    * Objetivo: Asegurar que los datos están bien preparados para el modelo.\n",
    "\n",
    "\n",
    "* 6. Feature engineering / extraction / selection:\n",
    "    * Feature Engineering (Opcional, si aporta valor)\n",
    "        * Crear nuevas variables derivadas\n",
    "        * Ingeniería de fechas, combinaciones de columnas, ratios, interacciones, por ejemplo en pandas to_datetime y accesores de fechas para extraer año, mes, día, número de la semana, hora, minuto.\n",
    "        * Ejemplo: si tenemos una columna ip podemos usar una base de datos que nos traiga la dirección o ubicación, país etc de esa IP y agregar esa información para enriquecer el dataset.\n",
    "\n",
    "    * Feature Extraction (Opcional, si se necesita reducción dimensional) (Transforma datos, genera nuevas columnas a partir de las que hay)\n",
    "        * PCA para reducción de dimensionalidad capturando la máxima varianza posible\n",
    "        * Vectorización de texto y/o Word embeddings (en NLP)\n",
    "\n",
    "    * Feature Selection (Opcional, si hay muchas variables irrelevantes) (No transforma datos, selecciona las mejores columnas)\n",
    "        * Métodos estadísticos: SelectKBest con f_classif, chi2, f_regression\n",
    "        * Métodos basados en modelos: RFE, feature importance\n",
    "\n",
    "    * Orden: Primero Feature Engineering, luego Feature Extraction (si es necesario), y después Feature Selection para reducir ruido.\n",
    "\n",
    "* 7. Modelado\n",
    "    * Crear modelos, decidir algoritmos a utilizar:\n",
    "         * Numérica continua ➝ Regresión\n",
    "            * Algoritmos: LinealRegression, KNeighborsRegressor, DecisionTreeRegressor, SVR, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "        * Categórica discreta ➝ Clasificación\n",
    "            * Algoritmos: LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier, SVC, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "    * Entrenar modelos (model.fit)\n",
    "    * Hacer predicciones (model.predict)\n",
    "    * Validación de modelos y comparativa (cross-validation, métricas, visualización de resultados y comparar tiempos de entrenamiento, tiempos de prediccion y distintas métricas de regresión o clasificación)\n",
    "    * Métricas:\n",
    "        * Regresión: R2, MAE, MSE, RMSE, MAPE\n",
    "        * Clasificación: accuracy, precision, recall, f1, jaccard, confusion_matrix, classification_report\n",
    "\n",
    "* Optimización del modelo\n",
    "    * Tuning de hiperparámetros\n",
    "        * GridSearchCV\n",
    "        * RandomizedSearchCV\n",
    "    * Encontrar la mejor configuración del modelo manteniendo bajo coste computacional.\n",
    "\n",
    "* Pipelines y producción\n",
    "    * Uso de pipelines para agrupar preprocesado y modelado\n",
    "    * Exportar modelo entrenado (pickle, joblib)\n",
    "    * Despliegue en producción (API, servicio en la nube, etc.)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
